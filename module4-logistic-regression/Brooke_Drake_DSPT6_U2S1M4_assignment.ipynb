{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Brooke_Drake_DSPT6_U2S1M4_assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iambrookedrake/DS-Unit-2-Linear-Models/blob/master/module4-logistic-regression/Brooke_Drake_DSPT6_U2S1M4_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69LpCEakiqEi",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "## Assignment ðŸŒ¯\n",
        "\n",
        "You'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- [ ] Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- [ ] Begin with baselines for classification.\n",
        "- [ ] Use scikit-learn for logistic regression.\n",
        "- [ ] Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- [ ] Get your model's test accuracy. (One time, at the end.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do one-hot encoding.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igaNjwOciqGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data downloaded from https://srcole.github.io/100burritos/\n",
        "import pandas as pd\n",
        "df = pd.read_csv(DATA_PATH+'burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB5APG7hiqHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive binary classification target:\n",
        "# We define a 'Great' burrito as having an\n",
        "# overall rating of 4 or higher, on a 5 point scale.\n",
        "# Drop unrated burritos.\n",
        "df = df.dropna(subset=['overall'])\n",
        "df['Great'] = df['overall'] >= 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFIEsANriqH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean/combine the Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MURPpkgViqIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some high cardinality categoricals\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpV_KYyUiqJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some columns to prevent \"leakage\"\n",
        "df = df.drop(columns=['Rec', 'overall'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftuQZlHXDwm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Open= 'Date', 'Cost', 'Mass (g)', 'Density (g/mL)', 'Length', 'Circum', 'Volume'\n",
        "Categ='Burrito','Yelp', 'Google',  'Hunger','Tortilla','Temp', 'Meat', 'Fillings', 'Meat:filling', 'Uniformity', 'Salsa', 'Synergy', 'Wrap'\n",
        "Closed= 'Chips', 'Unreliable', 'NonSD', 'Beef', 'Pico', 'Guac', 'Cheese', 'Fries', 'Sour cream', 'Pork', 'Chicken', 'Shrimp', 'Fish', 'Rice', 'Beans', 'Lettuce', 'Tomato', 'Bell peper', 'Carrots', 'Cabbage', 'Sauce', 'Salsa.1', 'Cilantro', 'Onion', 'Taquito', 'Pineapple', 'Ham', 'Chile relleno', 'Nopales', 'Lobster', 'Queso', 'Egg', 'Mushroom', 'Bacon', 'Sushi', 'Avocado', 'Corn', 'Zucchini'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsECi542aY29",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Deal with NaNs of Different types\n",
        "import numpy as np\n",
        "df = df.replace({'x':'y','X':'y','yes':'y','Yes':'y','no':'n','No':'n'})\n",
        "#for i in Open:\n",
        " # df[i] = df[i].replace(np.NaN,'?')\n",
        "#for i in Categ:\n",
        "  #df[i] = df[i].replace(np.NaN,'?')\n",
        "for i in Closed:\n",
        "  df[i] = df[i].replace(np.NaN,'n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qczJ-0nB74lw",
        "colab_type": "code",
        "outputId": "974055f2-c0b9-4f97-893a-650851ba0af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>87.000000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>414.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>283.000000</td>\n",
              "      <td>281.000000</td>\n",
              "      <td>281.000000</td>\n",
              "      <td>421.000000</td>\n",
              "      <td>401.000000</td>\n",
              "      <td>407.000000</td>\n",
              "      <td>418.000000</td>\n",
              "      <td>412.000000</td>\n",
              "      <td>419.000000</td>\n",
              "      <td>396.000000</td>\n",
              "      <td>419.000000</td>\n",
              "      <td>418.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.887356</td>\n",
              "      <td>4.167816</td>\n",
              "      <td>7.067343</td>\n",
              "      <td>3.495335</td>\n",
              "      <td>546.181818</td>\n",
              "      <td>0.675277</td>\n",
              "      <td>20.038233</td>\n",
              "      <td>22.135765</td>\n",
              "      <td>0.786477</td>\n",
              "      <td>3.519477</td>\n",
              "      <td>3.783042</td>\n",
              "      <td>3.620393</td>\n",
              "      <td>3.539833</td>\n",
              "      <td>3.586481</td>\n",
              "      <td>3.428998</td>\n",
              "      <td>3.371970</td>\n",
              "      <td>3.586993</td>\n",
              "      <td>3.979904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.475396</td>\n",
              "      <td>0.373698</td>\n",
              "      <td>1.506742</td>\n",
              "      <td>0.812069</td>\n",
              "      <td>144.445619</td>\n",
              "      <td>0.080468</td>\n",
              "      <td>2.083518</td>\n",
              "      <td>1.779408</td>\n",
              "      <td>0.152531</td>\n",
              "      <td>0.794438</td>\n",
              "      <td>0.980338</td>\n",
              "      <td>0.829254</td>\n",
              "      <td>0.799549</td>\n",
              "      <td>0.997057</td>\n",
              "      <td>1.068794</td>\n",
              "      <td>0.924037</td>\n",
              "      <td>0.886807</td>\n",
              "      <td>1.118185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>2.990000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>450.000000</td>\n",
              "      <td>0.619485</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>6.990000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>540.000000</td>\n",
              "      <td>0.658099</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.770000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>7.880000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>595.000000</td>\n",
              "      <td>0.721726</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>925.000000</td>\n",
              "      <td>0.865672</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>1.540000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Yelp     Google        Cost  ...       Salsa     Synergy        Wrap\n",
              "count  87.000000  87.000000  414.000000  ...  396.000000  419.000000  418.000000\n",
              "mean    3.887356   4.167816    7.067343  ...    3.371970    3.586993    3.979904\n",
              "std     0.475396   0.373698    1.506742  ...    0.924037    0.886807    1.118185\n",
              "min     2.500000   2.900000    2.990000  ...    0.000000    1.000000    0.000000\n",
              "25%     3.500000   4.000000    6.250000  ...    3.000000    3.000000    3.500000\n",
              "50%     4.000000   4.200000    6.990000  ...    3.500000    3.800000    4.000000\n",
              "75%     4.000000   4.400000    7.880000  ...    4.000000    4.000000    5.000000\n",
              "max     4.500000   5.000000   25.000000  ...    5.000000    5.000000    5.000000\n",
              "\n",
              "[8 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yezmwqZp742K",
        "colab_type": "code",
        "outputId": "60adf584-be35-4b22-c0d1-2c87a80b80b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "df.describe(exclude='number')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Date</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "      <td>421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>5</td>\n",
              "      <td>169</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>California</td>\n",
              "      <td>8/30/2016</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>169</td>\n",
              "      <td>29</td>\n",
              "      <td>396</td>\n",
              "      <td>388</td>\n",
              "      <td>414</td>\n",
              "      <td>242</td>\n",
              "      <td>263</td>\n",
              "      <td>267</td>\n",
              "      <td>262</td>\n",
              "      <td>294</td>\n",
              "      <td>329</td>\n",
              "      <td>370</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>415</td>\n",
              "      <td>385</td>\n",
              "      <td>386</td>\n",
              "      <td>410</td>\n",
              "      <td>414</td>\n",
              "      <td>414</td>\n",
              "      <td>420</td>\n",
              "      <td>413</td>\n",
              "      <td>383</td>\n",
              "      <td>414</td>\n",
              "      <td>406</td>\n",
              "      <td>404</td>\n",
              "      <td>417</td>\n",
              "      <td>414</td>\n",
              "      <td>419</td>\n",
              "      <td>417</td>\n",
              "      <td>417</td>\n",
              "      <td>420</td>\n",
              "      <td>421</td>\n",
              "      <td>416</td>\n",
              "      <td>418</td>\n",
              "      <td>418</td>\n",
              "      <td>419</td>\n",
              "      <td>408</td>\n",
              "      <td>418</td>\n",
              "      <td>420</td>\n",
              "      <td>239</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Burrito       Date Chips Unreliable  ... Avocado Corn Zucchini  Great\n",
              "count          421        421   421        421  ...     421  421      421    421\n",
              "unique           5        169     2          2  ...       2    2        2      2\n",
              "top     California  8/30/2016     n          n  ...       n    n        n  False\n",
              "freq           169         29   396        388  ...     408  418      420    239\n",
              "\n",
              "[4 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H68ugET66mAx",
        "colab_type": "code",
        "outputId": "8a5faa3d-4a52-47c4-bd58-e606b94b4c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##Do train/validate/test split. Train on reviews from 2016 & earlier. \n",
        "##Validate on 2017. Test on 2018 & later.\n",
        "import datetime\n",
        "from datetime import datetime, date, time\n",
        "df['year'] = df['Date']\n",
        "df['year'] = pd.to_datetime(df['year'], infer_datetime_format=True)\n",
        "df['year']=df['year'].dt.year\n",
        "train = df[df['year'] < 2017]\n",
        "val = df[df['year'] == 2017]\n",
        "test = df[df['year'] > 2017]\n",
        "print( train.shape, val.shape, test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(298, 60) (85, 60) (38, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1l_9yDC6nXL",
        "colab_type": "code",
        "outputId": "37c19750-36ae-4120-d005-fbe40dfc59a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Begin with baselines for classification.\n",
        "target = 'Great'\n",
        "y_train = train[target]\n",
        "y_train.value_counts(normalize=True)\n",
        "majority_class = y_train.mode()[0]\n",
        "y_train_pred = [majority_class]*len(y_train)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
        "\n",
        "print(f'Baseline accuracy: {accuracy_score(y_train, y_train_pred)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline accuracy: 0.5906040268456376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiOEdNqtj2nq",
        "colab_type": "code",
        "outputId": "35610816-2393-4ede-b2a6-98687efa8f6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "##Use scikit-learn for logistic regression.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression(solver='lbfgs')\n",
        "\n",
        "features = ['Cost', 'Length',  'Circum']\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_val_imputed = imputer.transform(X_val)\n",
        "\n",
        "log_reg.fit(X_train_imputed, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ94Xo4amMBk",
        "colab_type": "code",
        "outputId": "c2adae54-769d-46fe-95fa-07a82e84f950",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "#Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "\n",
        "y_val = val[target]\n",
        "y_pred = [majority_class]*len(val)\n",
        "\n",
        "y_pred = log_reg.predict(X_val_imputed)\n",
        "print(f'Validation accuracy: {accuracy_score(y_val, y_pred)}')\n",
        "y_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 0.5529411764705883\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False,  True, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False,  True,  True,\n",
              "       False, False, False, False,  True, False, False, False, False,\n",
              "       False,  True, False,  True, False, False, False, False, False,\n",
              "       False,  True, False, False, False, False, False, False, False,\n",
              "       False,  True,  True, False,  True,  True, False,  True, False,\n",
              "       False, False, False,  True, False, False,  True,  True, False,\n",
              "       False,  True, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-H-sOcHbSM8",
        "colab_type": "code",
        "outputId": "8ea78b84-2909-4692-e16b-9b539ec17324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "import category_encoders as ce \n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "encoder = ce.one_hot.OneHotEncoder(use_cat_names=True)\n",
        "X_train_enc = encoder.fit_transform(X_train)\n",
        "X_val_enc = encoder.transform(X_val)\n",
        "\n",
        "imputer = SimpleImputer()\n",
        "X_train_imp = imputer.fit_transform(X_train_enc)\n",
        "X_val_imp = imputer.transform(X_val_enc)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_sc = scaler.fit_transform(X_train_imp)\n",
        "X_val_sc = scaler.transform(X_val_imp)\n",
        "\n",
        "X_train_sc = pd.DataFrame(X_train_sc, columns=X_train_enc.columns)\n",
        "X_val_sc = pd.DataFrame(X_val_sc, columns=X_val_enc.columns)\n",
        "X_train_sc.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cost</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.339805</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.208571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.709783</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.375642</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.256270</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Cost  Length  Circum\n",
              "0 -0.339805     0.0     0.0\n",
              "1 -1.208571     0.0     0.0\n",
              "2 -1.709783     0.0     0.0\n",
              "3 -1.375642     0.0     0.0\n",
              "4 -0.256270     0.0     0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0XEq8SK6niv",
        "colab_type": "code",
        "outputId": "ff125252-3bea-47a2-86e6-b135a7a550b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegressionCV()\n",
        "model.fit(X_train_sc, y_train)\n",
        "y_pred = model.predict(X_val_sc)\n",
        "print(f'Validation accuracy: {accuracy_score(y_val, y_pred)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy: 0.5529411764705883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQbmbs7EkWO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Get your model's test accuracy. (One time, at the end.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCFw2VF06nnu",
        "colab_type": "code",
        "outputId": "becf2b1e-d9f4-43fe-d013-9b7111768b8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_case = [[8,22,23]]  # $8 Burrito, 22cm long 23cm circumference (upper 75%ile)\n",
        "log_reg.predict(test_case)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnKO8_58ZtMa",
        "colab_type": "code",
        "outputId": "f1b0efeb-794c-4e05-9cac-be4fd6601a8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(log_reg.predict(test_case))\n",
        "print(log_reg.predict_proba(test_case))\n",
        "print(log_reg.coef_)\n",
        "print(log_reg.intercept_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ True]\n",
            "[[0.49109357 0.50890643]]\n",
            "[[0.24121425 0.05820616 0.01740458]]\n",
            "[-3.57492528]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOWZ9J7naDEq",
        "colab_type": "code",
        "outputId": "f66d47c4-cd67-46c7-dc5d-f17278a81575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.e**(-x))\n",
        "\n",
        "print(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case)))\n",
        "sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.03562949]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.50890643]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ_pP9CWcQDs",
        "colab_type": "code",
        "outputId": "4f6b9d66-b733-4592-99e5-d083498e262d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "##Stretch: Get and plot your coefficients.\n",
        "coefs = model.coef_[0]\n",
        "coefs = pd.Series(coefs, X_train_sc.columns)\n",
        "coefs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Cost      0.002045\n",
              "Length    0.000507\n",
              "Circum    0.000740\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fh9tkf6TcRtK",
        "colab_type": "code",
        "outputId": "fc3eb70b-9b59-449e-ce7e-fbd516b8ab71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "coefs.sort_values().plot.barh()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8c32c16c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD4CAYAAAAHHSreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAPPElEQVR4nO3dfZBddX3H8feXBAJp5EFIYYvWFYY+gDwIkSkKDFhrkVgpD620jMJUzVilU+pYhTLTOm2ZRh3HjC3KxA4GKwUECkMBbSkg0DoUEkoSQFEe0kKEdIASSKsY4Ns/7llyc797N3c3u+eG8H7N3Nmzv3PO73z3t2fP555z7t4bmYkkSd12GHYBkqRtj+EgSSoMB0lSYThIkgrDQZJUzB52AdNhr732ytHR0WGXIUmvKitWrHgqM+ePN2+7CIfR0VGWL18+7DIk6VUlIv6z3zwvK0mSCsNBklQYDpKkwnCQJBWGgySpMBwkSYXhIEkqDAdJUmE4SJIKw0GSVBgOkqTCcJAkFYaDJKkwHCRJheEgSSoMB0lSsV182M/qtesZPfeGYZchSa1as3jhjPXtmYMkqTAcJEmF4SBJKgwHSVJhOEiSCsNBklQYDpKkwnCQJBWGgySpMBwkSYXhIEkqDAdJUmE4SJIKw0GSVMxYOETEPhFxeUQ8HBErIuLGiPiFSfbxJzNVnySpvxkJh4gI4BrgO5m5f2YeAZwH7D3JrgwHSRqCmTpzOB7YmJkXjTVk5krgXyPi8xFxX0Ssjoj3A0TESETcHhH3NvOOiYjFwC5N26UzVKckaRwz9UlwbwFWjNN+CnAYcCiwF3B3RNwO/C7wT5l5QUTMAuZm5h0RcXZmHjZDNUqS+mj7Y0KPBi7LzJeAdRFxG/A24G7g4ojYEbg2M+/dUkcRsQhYBDBr1/kzWLIkvfbM1GWl+4EjBl04M28HjgXWAssi4oMDrLM0Mxdk5oJZc3ebeqWSpGKmwuEWYE7z7B6AiDgEeBZ4f0TMioj5dALhroh4E7AuM78K/C1weLPaxuZsQpLUohm5rJSZGREnA0si4tPAT4A1wDnAPGAlkMCnMvPJiDgT+OOI2AhsAMbOHJYCqyLinsw8YyZqlSRVkZnDrmGrzRk5IEfOXDLsMiSpVWsWL9yq9SNiRWYuGG+e/yEtSSoMB0lSYThIkgrDQZJUGA6SpMJwkCQVhoMkqTAcJEmF4SBJKgwHSVJhOEiSCsNBklQYDpKkou1PgpsRB++7G8u38t0JJUmbeOYgSSoMB0lSYThIkgrDQZJUGA6SpMJwkCQVhoMkqTAcJEmF4SBJKgwHSVJhOEiSCsNBklQYDpKkwnCQJBWGgySpMBwkSYXhIEkqDAdJUmE4SJIKw0GSVBgOkqTCcJAkFYaDJKkwHCRJheEgSSoMB0lSYThIkgrDQZJUGA6SpMJwkCQVhoMkqTAcJEmF4SBJKgwHSVJhOEiSitnDLmA6rF67ntFzbxh2GZomaxYvHHYJ0mueZw6SpMJwkCQVhoMkqTAcJEmF4SBJKgwHSVJhOEiSCsNBklQYDpKkwnCQJBWGgySpMBwkSYXhIEkqDAdJUjFQOETEPhFxeUQ8HBErIuLGiDg2Iq6a6QIlSe3b4uc5REQA1wCXZObpTduhwK6Zedo4y8/OzBenvVJJUmsGOXM4HtiYmReNNWTmSuCxiLgPICLOiojrIuIW4OaImBcRX4uI1RGxKiJObZbbMNZHRJwWEcua6WUR8ZWIuDMiHomI4yLi4oj43tgykqT2DPJJcG8BVgyw3OHAIZn5TER8FlifmQcDRMQeA6y/B3AU8D7gOuAdwIeBuyPisMy8t3vhiFgELAKYtev8AbqXJA1qOm9I35SZzzTT7wIuHJuRmf8zwPr/mJkJrAbWZebqzHwZuB8Y7V04M5dm5oLMXDBr7m5bX70k6RWDhMP9wBEDLPe/AyyTXdM798x7ofn6ctf02PfbxWddS9KrxSDhcAswp7mMA0BEHAK8cYJ1bgI+3rX82GWldRHxyxGxA3DyFOqVJLVgi+HQXOo5GXhX81LW+4G/Ap6cYLW/BPaIiPsiYiWdm9oA5wLXA98FntiqyiVJMyY6x/5XtzkjB+TImUuGXYamyZrFC4ddgvSaEBErMnPBePP8D2lJUmE4SJIKw0GSVBgOkqTCcJAkFYaDJKkwHCRJheEgSSoMB0lSYThIkgrDQZJUGA6SpGK7+JyEg/fdjeW+WZskTRvPHCRJheEgSSoMB0lSYThIkgrDQZJUGA6SpMJwkCQVhoMkqTAcJEmF4SBJKgwHSVJhOEiSCsNBklQYDpKkwnCQJBWGgySpMBwkSYXhIEkqDAdJUmE4SJIKw0GSVBgOkqTCcJAkFYaDJKkwHCRJheEgSSoMB0lSYThIkgrDQZJUGA6SpMJwkCQVhoMkqTAcJEmF4SBJKgwHSVIxe9gFTIfVa9czeu4Nwy7jVWnN4oXDLkHSNsgzB0lSYThIkgrDQZJUGA6SpMJwkCQVhoMkqTAcJEmF4SBJKgwHSVJhOEiSCsNBklQYDpKkwnCQJBWGgySpGCgcImLDTBYREedExNy2tidJmti2cuZwDjB3i0tJklox5Q/7iYj9gQuB+cD/AR/JzO9HxDLgOWABsA/wqcy8KiJ2AP4GeCfwGLARuBj4ueZxa0Q8lZnHN/1fALwX+DFwUmaum2qtkqTJ2Zozh6XAH2TmEcAngS93zRsBjqZzcF/ctJ0CjAIHAh8AjgLIzC8BPwKOHwsG4GeAOzPzUOB24CNbUackaZKmdOYQEfOAtwNXRsRY85yuRa7NzJeBByJi76btaODKpv3JiLh1gk38FLi+mV4B/No4NSwCFgHM2nX+VH4MSVIfU72stAPwbGYe1mf+C13T0WeZiWzMzGymX2KcOjNzKZ2zF+aMHJC98yVJUzely0qZ+RzwaET8FkB0HLqF1f4NODUidmjOJo7rmvc88Lqp1CJJmn6DhsPciHi86/EJ4AzgQxGxErgfOGkLfVwNPA48AHwDuAdY38xbCnx7C5eaJEktiU1Xb1rYWMS8zNwQEXsCdwHvyMwnt7bfOSMH5MiZS7a+wNegNYsXDrsESUMSESsyc8F486b8UtYpuj4idgd2Av5iOoJBkjT9Wg2HzDyuze1JkqZmW/kPaUnSNsRwkCQVhoMkqTAcJEmF4SBJKgwHSVJhOEiSCsNBklQYDpKkwnCQJBWGgySpaPuN92bEwfvuxnLfXVSSpo1nDpKkwnCQJBWGgySpMBwkSYXhIEkqDAdJUmE4SJIKw0GSVBgOkqTCcJAkFYaDJKkwHCRJheEgSSoMB0lSYThIkgrDQZJUGA6SpCIyc9g1bLWIeB54cNh19LEX8NSwi+jD2qbG2qbG2qZmJmt7U2bOH2/GdvExocCDmblg2EWMJyKWW9vkWdvUWNvUWFvlZSVJUmE4SJKK7SUclg67gAlY29RY29RY29RYW4/t4oa0JGl6bS9nDpKkaWQ4SJKqzBzaAziBzv8nPAScO878OcAVzfx/B0a75p3XtD8I/PqW+gTe3PTxUNPnTv220XJdlzbt9wEXAzs27ccB64F7m8efDmHMlgGPdtVwWNMewJea5VcBhw+htju66voRcO0Qxu1i4L+B+3r6ej1wE/DD5useQxi3frV9Hvh+s/1rgN2b9lHgx13jdtEQavsMsLarhhMn6qvl2q7oqmsNcG+b4wa8EbgVeAC4H/jDqe5vAx+fJ7PwdD6AWcDDwH7ATsBK4MCeZT7WNdinA1c00wc2y8+hc9B/uOmvb5/AN4HTm+mLgN/vs41vtlzXic0vMYDLuuo6Drh+yGO2DDhtnN/dicC3mpp/hc7O3WptPf1eDXywzXFr5h0LHE49kHyO5oAAnAt8ts1x20Jt7wZmN9Of7aptdJxl267tM8Anx/n9jtfXjm3W1tPvF9j0pKOVcQNG2PRk4nXAD9j0dzrw/jaZY/QwLysdCTyUmY9k5k+By4GTepY5Cbikmb4K+NWIiKb98sx8ITMfpZOMR/brs1nnnU0fNH3+Zp9tvLutugAy88ZsAHcBb9gWxmyCGsa28fWm7DuB3YH3DKO2iNiVzu/22gnqnYlxIzNvB57pMz5jffXua22MW9/aMvOfM/PF5ts7aX9/m2jc+hmvr7OGUVuz/m/TeSLXz7SPW2Y+kZn3NDU+D3wP2Hecvibc3yJiZIK6NzPMcNgXeKzr+8fZ9MOWZZodej2w5wTr9mvfE3i264+ie1u92/gJndPKNup6RUTsCHwA+HZX81ERsTIivhURBw3SzwzUdkFErIqIL0bEnN5tdK1z4BBqg84fws2Z+VxXWxvjNpG9M/OJZvpJYO/ebXT1NRPjNqjfo/PMcsybI+I/IuK2iDhmwP6nu7azm/3t4ojYo3cbXX394hBqAzgGWJeZP+xqa3XcImIUeCudM0+Y3P428P7hDeltx5eB2zPzjub7e+i878mhwF8z8TPjmXIe8EvA2+hc1/z0EGrYkt9h82dx28K4vaI5I8xh1jCeiDgfeJHOPS+AJ4Cfz8y3Ap8A/h7YpeWyvgLsDxzW1POFlrc/iN79rdVxi4h5dC6jntPzhAiY3v1tmOGwls5NljFvaNrGXSYiZgO7AU9PsG6/9qfpnFLN7mkfbxs7Az/bUl00ffwZMJ/OzgVAZj6XmRua6RvpXGPdMFE/011bcyqbmfkC8DWaU+8+6zzQZm1NH3s1Nd0w1tbiuE1k3djpe/N17Ey0rXGbUEScBbwXOKM5mNBcxni6mV5B51r37DZry8x1mflSZr4MfJWJ97cH26ytq49T6NxIHqu5tXFrri5cDVyamf/Qtcxk9rct/pyvyEncoJjORzOAj9C56TJ20+agnmU+Ts/N4mb6IDa/afMInZs2ffsErmTzG9If67ONK1uu68PAd4FderaxD5v+SfFI4L+GMGYjzdcAlgCLm+8XsvmNrrvarq1Z76PAJcMYt671Rhn/FUHdNwg/1+a4baG2E+gE0vye9vlsuim7H52DyPyWaxvpmv4jOtfe+/W1U5u1dY3dbcMYt2af+TqwZJy6Bt7fJnWMnurBfToedO6m/4BO2p7ftP058L5memc6B+uH6Pwh7de17vnNeg8C75moz65f3F1NX1cCc/pto+W6Xmzael96eTadl6ytpHPj8O1DGLNbgNV0Xmb7DWBe0x7Ahc3yq4EFbdfWzPsOcEJPW5vjdhmdywob6VzP/VDTvidwM52XFv4L8PohjFu/2h6icx2696WXpzbjdi+dS3O/MYTa/q4Zl1XAdWweFqWvNmtr5i0DPtqzv7UybsDRdC4XraLnpb5Mcn8b9OHbZ0iSCm9IS5IKw0GSVBgOkqTCcJAkFYaDJKkwHCRJheEgSSr+H86PKy4qESYcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}